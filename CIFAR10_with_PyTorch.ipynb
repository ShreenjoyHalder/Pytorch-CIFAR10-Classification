{"cells":[{"cell_type":"markdown","source":["### Imports and Setup for Image Classification in PyTorch"],"metadata":{"id":"uXPA_4lJrdSN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sNtAhSjjyE4K"},"outputs":[],"source":["import os\n","import torch\n","import torchvision\n","import tarfile\n","import torch.nn as nn\n","import numpy as np\n","import torch.nn.functional as F\n","from torchvision.datasets.utils import download_url\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as tt\n","from torch.utils.data import random_split\n","from torchvision.utils import make_grid\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","matplotlib.rcParams['figure.facecolor']='#ffffff'"]},{"cell_type":"markdown","source":["### Download the CIFAR-10 dataset\n","`dataset_url` stores the URL of the CIFAR-10 `.tgz` archive. `download_url` downloads it to the current directory."],"metadata":{"id":"lU0u9T2atKe6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Y_T5wVZz6Xq"},"outputs":[],"source":["dataset_url=\"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n","download_url(dataset_url, '.')\n","\n","with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n","  tar.extractall(path='./data')\n","\n","data_dir=\"./data/cifar10\"\n","print(os.listdir(data_dir))\n","\n","classes=os.listdir(data_dir + \"/train\")\n","print(classes)"]},{"cell_type":"markdown","source":["### Define image augmentation and preprocessing for training\n","Applies standard image augmentation and preprocessing to make the model generalize better :\n","- `RandomCrop` : Randomly crops a `32*32` region with reflection padding.\n","- `RandomHorizontalFlip` : Randomly flips the image horizontally.\n","- `ToTensor` : Converts the image to a PyTorch tensor.\n","- `Normalize` : Standardizes pixel values using the given channel-wise mean and std."],"metadata":{"id":"IopcE7LGv1wG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"I1XUS7QQ1dzH"},"outputs":[],"source":["stats=((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","train_and_val_tfms=tt.Compose([tt.RandomCrop(32, padding=4, padding_mode='reflect'),\n","                       tt.RandomHorizontalFlip(),\n","                       tt.RandomRotation(10),\n","                       tt.ToTensor(),\n","                       tt.Normalize(*stats, inplace=True)])\n","test_tfms=tt.Compose([tt.ToTensor(), tt.Normalize(*stats, inplace=True)])"]},{"cell_type":"markdown","source":["### Create the datasets\n","Loads the CIFAR-10 images from folders using `ImageFolder`.\n","\n","Each subfolder name is treated as the class label.\n","\n","Applies respective transformations to training and validation sets."],"metadata":{"id":"QIH7gyNawWzw"}},{"cell_type":"code","source":["train_and_val_ds=ImageFolder(data_dir+'/train', train_and_val_tfms)\n","test_ds=ImageFolder(data_dir+'/test', test_tfms)\n","\n","train_size=int(0.8*len(train_and_val_ds))\n","val_size=len(train_and_val_ds)-train_size\n","\n","training_ds, validation_ds=random_split(train_and_val_ds, [train_size, val_size])"],"metadata":{"id":"HzmtkNcL3RqZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create data loaders\n","Wraps the datasets with `DataLoader` to enable efficient mini-batch processing :\n","\n","- `batch_size = 128` : Loads data in batches of 128 samples.\n","- `shuffle=True` : Randomizes the order of training data for better generalization.\n","- `num_workers=2` : Loads data in parallel using 2 subprocesses to improve speed.\n","- `pin_memory=True` : Speeds up data transfer to GPU (if using CUDA)."],"metadata":{"id":"zOqoQW0Ry4QY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"89aMlWI-1Fvm"},"outputs":[],"source":["batch_size=128\n","training_dl=DataLoader(training_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n","validation_dl=DataLoader(validation_ds, batch_size, num_workers=2, pin_memory=True)\n","test_dl=DataLoader(test_ds, batch_size, num_workers=2, pin_memory=True)"]},{"cell_type":"markdown","metadata":{"id":"cxMlY1y4h2ls"},"source":["### Define a denormalization function\n","Reverses the normalization applied to image tensors so they can be visualized correctly."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iXbGOAjX-tLG"},"outputs":[],"source":["def denormalize(images, means, stds):\n","  means=torch.tensor(means).reshape(1, 3, 1, 1)\n","  stds=torch.tensor(stds).reshape(1, 3, 1, 1)\n","  return images*stds+means"]},{"cell_type":"markdown","source":["### Let us see data of a batch"],"metadata":{"id":"8-NnIBxZzSDD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"q3AkahQu_biH"},"outputs":[],"source":["def show_batch(dl):\n","  for i, _ in dl:\n","    fig, ax=plt.subplots(figsize=(16, 8))\n","    ax.set_xticks([])\n","    ax.set_yticks([])\n","    denorm_i=denormalize(i, *stats)\n","    ax.imshow(make_grid(denorm_i, nrow=16).permute(1, 2, 0).clamp(0, 1))\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pgw95ll1Abga"},"outputs":[],"source":["show_batch(training_dl)"]},{"cell_type":"markdown","source":["### Load data batches onto GPU (if available)"],"metadata":{"id":"vvccnVZ5zscp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKAOnFHTAd4H"},"outputs":[],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZDpz7ScpBLFB"},"outputs":[],"source":["def default_device():\n","  if torch.cuda.is_available():\n","    return torch.device(\"cuda\")\n","  return torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpS0dbaiBNMb"},"outputs":[],"source":["device=default_device()\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xh5uKIbnBPGg"},"outputs":[],"source":["def to_device(data, device):\n","  if isinstance(data, (list, tuple)):\n","    return [to_device(x, device) for x in data]\n","  return data.to(device, non_blocking=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7upIhreXBUG2"},"outputs":[],"source":["for i, _ in training_dl:\n","  print(i.shape)\n","  print(i.device)\n","  i=to_device(i, device)\n","  print(i.device)\n","  break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"leaFdD3YBWKd"},"outputs":[],"source":["class deviceDataLoader():\n","\n","  def __init__(self, dl, device):\n","    self.dl=dl\n","    self.device=device\n","\n","  def __iter__(self):\n","    for i in self.dl:\n","      yield to_device(i, self.device)\n","\n","  def __len__(self):\n","    return len(self.dl)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fIrFdZ2sBZoN"},"outputs":[],"source":["device=default_device()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ihdgTLndBo3I"},"outputs":[],"source":["training_dl=deviceDataLoader(training_dl, device)\n","validation_dl=deviceDataLoader(validation_dl, device)"]},{"cell_type":"markdown","metadata":{"id":"uahbnfQdh8St"},"source":["### An example of a simple residual block"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OJqvhq3-B23O"},"outputs":[],"source":["class simpleResidualBlock(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.c1=nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1)\n","    self.r1=nn.ReLU()\n","    self.c2=nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1)\n","    self.r2=nn.ReLU()\n","\n","  def forward(self, x):\n","    out=self.c1(x)\n","    out=self.r1(out)\n","    out=self.c2(out)\n","    return self.r2(out)+x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3FunRJbPFpNu"},"outputs":[],"source":["simpleResnet=to_device(simpleResidualBlock(), device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O1aR9SShF9vA"},"outputs":[],"source":["for i, _ in training_dl:\n","  print(i.shape)\n","  out=simpleResnet(i)\n","  print(out.shape)\n","  break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-uV6Ux-jGKzW"},"outputs":[],"source":["del simpleResnet, i, _\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","source":["### Define accuracy metric\n","Calculates the accuracy of model predictions compared to the true labels."],"metadata":{"id":"tGHnqvrj0ODK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9h_Bmy7sHDJT"},"outputs":[],"source":["def accuracy(output, label):\n","  _, prediction=torch.max(output, dim=1)\n","  return torch.tensor(torch.sum(prediction==label).item()/len(prediction))"]},{"cell_type":"markdown","source":["### Define a base class for image classification models\n","This base class extends `nn.Module` and includes standard training and evaluation methods used in image classification tasks."],"metadata":{"id":"9o9o9TtO0i3t"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NH1cnNquHHbL"},"outputs":[],"source":["class imageClassiicationBase(nn.Module):\n","\n","  def training_step(self, batch):\n","    image, label=batch\n","    out=self(image)\n","    loss=F.cross_entropy(out, label)\n","    return loss\n","\n","  def validation_step(self, batch):\n","    image, label=batch\n","    out=self(image)\n","    loss=F.cross_entropy(out, label)\n","    acc=accuracy(out, label)\n","    return {\"Loss\":loss, \"Accuracy\":acc}\n","\n","  def validation_epoch_end(self, output):\n","    all_batch_loss=[i['Loss'] for i in output]\n","    all_batch_acc=[i['Accuracy'] for i in output]\n","    mean_loss=torch.stack(all_batch_loss).mean()\n","    mean_acc=torch.stack(all_batch_acc).mean()\n","    return {\"Mean_loss\":mean_loss, \"Mean_accuracy\":mean_acc}\n","\n","  def epoch_end(self, epoch, result):\n","    print(f'Epoch : {epoch}, Mean_loss : {result[\"Mean_loss\"]:.4f}, Mean_accuracy : {result[\"Mean_accuracy\"]:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"l-mIPN6-iGEV"},"source":["### ResNet9 implementation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0gSXtQ0ZO0vW"},"outputs":[],"source":["def convBlock(in_c, out_c, pool=False):\n","  layers=[nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n","          nn.BatchNorm2d(out_c),\n","          nn.ReLU(inplace=True)]\n","  if pool:\n","    layers.append(nn.MaxPool2d(2))\n","  return nn.Sequential(*layers)\n","\n","class ResNet9(imageClassiicationBase):\n","  def __init__(self, in_c, num_classes):\n","    super().__init__()\n","\n","    self.c1=convBlock(in_c, 64)\n","    self.c2=convBlock(64, 128, pool=True)\n","    self.r1=nn.Sequential(convBlock(128, 128), convBlock(128, 128))\n","\n","    self.c3=convBlock(128, 256, pool=True)\n","    self.c4=convBlock(256, 512, pool=True)\n","    self.r2=nn.Sequential(convBlock(512, 512), convBlock(512, 512))\n","\n","    self.classifier=nn.Sequential(nn.MaxPool2d(4),\n","                                  nn.Flatten(),\n","                                  nn.Dropout(0.2),\n","                                  nn.Linear(512, num_classes))\n","\n","  def forward(self, batch):\n","    out=self.c1(batch)\n","    out=self.c2(out)\n","    out=self.r1(out)+out\n","    out=self.c3(out)\n","    out=self.c4(out)\n","    out=self.r2(out)+out\n","    out=self.classifier(out)\n","    return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYSAk8W5SCtH"},"outputs":[],"source":["model=to_device(ResNet9(3, 10), device)\n","model"]},{"cell_type":"markdown","metadata":{"id":"HMRuH_jBjHgZ"},"source":["### Evaluate model on validation set\n","Sets the model to evaluation mode and disables gradient tracking.\n","\n","Calls `validation_step` on each batch and aggregates results using `validation_epoch_end`.\n","\n","The function `fit_one_cycle` is a training loop in deep learning that uses the One Cycle Policy for learning rate scheduling."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N_lolQAKSJwQ"},"outputs":[],"source":["def evaluate(model, validate_loader):\n","  model.eval()\n","  with torch.no_grad():\n","    output=[model.validation_step(batch) for batch in validate_loader]\n","  return model.validation_epoch_end(output)\n","\n","def get_lr(optimizer):\n","  for i in optimizer.param_groups:\n","    return i['lr']\n","\n","def fit_one_cycle(epoch, max_lr, model, train_loader, validate_loader, wt_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n","\n","  torch.cuda.empty_cache()\n","  history=[]\n","  optimizer=opt_func(model.parameters(), max_lr, weight_decay=wt_decay)\n","  sched=torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch, steps_per_epoch=len(training_dl))\n","\n","  for i in range(epoch):\n","\n","    model.train()\n","    losses=[]\n","    lrs=[]\n","\n","    for batch in train_loader:\n","      optimizer.zero_grad()\n","      loss=model.training_step(batch)\n","      losses.append(loss)\n","      loss.backward()\n","\n","      if grad_clip:\n","        nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","\n","      optimizer.step()\n","      lrs.append(get_lr(optimizer))\n","      sched.step()\n","\n","    result=evaluate(model, validate_loader)\n","    result[\"Training_loss\"]=torch.stack(losses).mean().item()\n","    result[\"LRs\"]=lrs\n","    model.epoch_end(i+1, result)\n","    history.append(result)\n","  return history"]},{"cell_type":"markdown","source":["### Training phase"],"metadata":{"id":"L8jtWQMU1NHn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-t2CamEMTdgW"},"outputs":[],"source":["result_0=evaluate(model, validation_dl)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0px82foTTz6"},"outputs":[],"source":["result_0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Uuz1sCTTXJh"},"outputs":[],"source":["epoch=10\n","max_lr=0.01\n","grad_clip=0.1\n","wt_decay=10**(-4)\n","opt_func=torch.optim.Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ewy7FwSuXjTV"},"outputs":[],"source":["history=fit_one_cycle(epoch, max_lr, model, training_dl, validation_dl, wt_decay, grad_clip, opt_func)"]},{"cell_type":"markdown","source":["### Evaluation of accuracy"],"metadata":{"id":"-3nZ3apj1Sd3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sx19jfPjaQkg"},"outputs":[],"source":["accuracies=[i[\"Mean_accuracy\"] for i in history]\n","plt.plot(accuracies, \"r.-\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Graph of accuracy against epoch\")\n","plt.show()"]},{"cell_type":"markdown","source":["### Compare the losses"],"metadata":{"id":"h4zdTtoT1YyC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3pDoN710JCA"},"outputs":[],"source":["mean_losses=[i[\"Mean_loss\"].item() for i in history]\n","training_losses=[i[\"Training_loss\"] for i in history]\n","plt.plot(mean_losses, \"b.-\", label=\"validation_loss\")\n","plt.plot(training_losses, \"k.-\", label=\"training_loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Graph of loss against epoch\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","source":["### Learning rate scheduling graph"],"metadata":{"id":"XZNp4BtM1eC-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JyqRHMts0I-a"},"outputs":[],"source":["lrs=[i for j in history for i in j[\"LRs\"]]\n","plt.plot(lrs, \"y-\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Learning rate\")\n","plt.title(\"Graph of average Learning rate against epoch\")\n","plt.show()"]},{"cell_type":"code","source":["test_dl=deviceDataLoader(test_dl, device)"],"metadata":{"id":"M77YBj4zLMjA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Prediction accuracy"],"metadata":{"id":"KQAjLLizOq5H"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Z-b-pq701Sj"},"outputs":[],"source":["output=evaluate(model, test_dl)"]},{"cell_type":"code","source":["output"],"metadata":{"id":"_B0uxzKa_3TI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## The Model can hit 87-90% accuracy on datasets like `CIFAR10` in under 5-6 minutes."],"metadata":{"id":"iTuM4KEBOvFa"}},{"cell_type":"code","source":[],"metadata":{"id":"G227ag_-MyrP"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyMBJCGWbizX9CE/1DTR2dmZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}